{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=KEY, model_name=\"gpt-3.5-turbo-0125\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001E333E48490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001E333E4E9A0>, model_name='gpt-3.5-turbo-0125', temperature=0.5, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(\n",
    "    llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"], template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(\n",
    "    llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = (\n",
    "    r\"D:\\Data Project\\MCQ Generator by Langchain & OpenAI (Generative AI)\\data.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) represent a breakthrough in artificial intelligence, employing neural network techniques with extensive parameters for advanced language processing.\n",
      "This article explores the evolution, architecture, applications, and challenges of LLMs, focusing on their impact in the field of Natural Language Processing (NLP).\n",
      "What are Large Language Models(LLMs)?\n",
      "A large language model is a type of artificial intelligence algorithm that applies neural network techniques with lots of parameters to process and understand human languages or text using self-supervised learning techniques. Tasks like text generation, machine translation, summary writing, image generation from texts, machine coding, chat-bots, or Conversational AI are applications of the Large Languag.e Model. Examples of such LLM models are Chat GPT by open AI, BERT (Bidirectional Encoder Representations from Transformers) by Google, etc.\n",
      "There are many techniques that were tried to perform natural language-related tasks but the LLM is purely based on the deep learning methodologies. LLM (Large language model) models are highly efficient in capturing the complex entity relationships in the text at hand and can generate the text using the semantic and syntactic of that particular language in which we wish to do so.\n",
      " Author-generated image with the use of AI\n",
      "LLM Models\n",
      "If we talk about the size of the advancements in the GPT (Generative Pre-trained Transformer) model only then:\n",
      "â€¢\tGPT-1 which was released in 2018 contains 117 million parameters having 985 million words.\n",
      "â€¢\tGPT-2 which was released in 2019 contains 1.5 billion parameters.\n",
      "â€¢\tGPT-3 which was released in 2020 contains 175 billion parameters. Chat GPT is also based on this model as well.\n",
      "â€¢\tGPT-4 model is expected to be released in the year 2023 and it is likely to contain trillions of parameters.\n",
      "How do Large Language Models work?\n",
      "Large Language Models (LLMs) operate on the principles of deep learning, leveraging neural network architectures to process and understand human languages. \n",
      "These models, are trained on vast datasets using self-supervised learning techniques. The core of their functionality lies in the intricate patterns and relationships they learn from diverse language data during training. LLMs consist of multiple layers, including feedforward layers, embedding layers, and attention layers. They employ attention mechanisms, like self-attention, to weigh the importance of different tokens in a sequence, allowing the model to capture dependencies and relationships. \n",
      "Architecture of LLM\n",
      "A Large Language Model's (LLM) architecture is determined by a number of factors, like the objective of the specific model design, the available computational resources, and the kind of language processing tasks that are to be carried out by the LLM. The general architecture of LLM consists of many layers such as the feed forward layers, embedding layers, attention layers. A text which is embedded inside is collaborated together to generate predictions.\n",
      "Important components to influence Large Language Model architecture  - \n",
      "â€¢\tModel Size and Parameter Count\n",
      "â€¢\tinput representations\n",
      "â€¢\tSelf-Attention Mechanisms\n",
      "â€¢\tTraining Objectives\n",
      "â€¢\tComputational Efficiency\n",
      "â€¢\tDecoding and Output Generation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the Python dictionary into a JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 5\n",
    "SUBJECT = \"large language model\"\n",
    "TONE = \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Large Language Models (LLMs) represent a breakthrough in artificial intelligence, employing neural network techniques with extensive parameters for advanced language processing.\n",
      "This article explores the evolution, architecture, applications, and challenges of LLMs, focusing on their impact in the field of Natural Language Processing (NLP).\n",
      "What are Large Language Models(LLMs)?\n",
      "A large language model is a type of artificial intelligence algorithm that applies neural network techniques with lots of parameters to process and understand human languages or text using self-supervised learning techniques. Tasks like text generation, machine translation, summary writing, image generation from texts, machine coding, chat-bots, or Conversational AI are applications of the Large Languag.e Model. Examples of such LLM models are Chat GPT by open AI, BERT (Bidirectional Encoder Representations from Transformers) by Google, etc.\n",
      "There are many techniques that were tried to perform natural language-related tasks but the LLM is purely based on the deep learning methodologies. LLM (Large language model) models are highly efficient in capturing the complex entity relationships in the text at hand and can generate the text using the semantic and syntactic of that particular language in which we wish to do so.\n",
      " Author-generated image with the use of AI\n",
      "LLM Models\n",
      "If we talk about the size of the advancements in the GPT (Generative Pre-trained Transformer) model only then:\n",
      "â€¢\tGPT-1 which was released in 2018 contains 117 million parameters having 985 million words.\n",
      "â€¢\tGPT-2 which was released in 2019 contains 1.5 billion parameters.\n",
      "â€¢\tGPT-3 which was released in 2020 contains 175 billion parameters. Chat GPT is also based on this model as well.\n",
      "â€¢\tGPT-4 model is expected to be released in the year 2023 and it is likely to contain trillions of parameters.\n",
      "How do Large Language Models work?\n",
      "Large Language Models (LLMs) operate on the principles of deep learning, leveraging neural network architectures to process and understand human languages. \n",
      "These models, are trained on vast datasets using self-supervised learning techniques. The core of their functionality lies in the intricate patterns and relationships they learn from diverse language data during training. LLMs consist of multiple layers, including feedforward layers, embedding layers, and attention layers. They employ attention mechanisms, like self-attention, to weigh the importance of different tokens in a sequence, allowing the model to capture dependencies and relationships. \n",
      "Architecture of LLM\n",
      "A Large Language Model's (LLM) architecture is determined by a number of factors, like the objective of the specific model design, the available computational resources, and the kind of language processing tasks that are to be carried out by the LLM. The general architecture of LLM consists of many layers such as the feed forward layers, embedding layers, attention layers. A text which is embedded inside is collaborated together to generate predictions.\n",
      "Important components to influence Large Language Model architecture  - \n",
      "â€¢\tModel Size and Parameter Count\n",
      "â€¢\tinput representations\n",
      "â€¢\tSelf-Attention Mechanisms\n",
      "â€¢\tTraining Objectives\n",
      "â€¢\tComputational Efficiency\n",
      "â€¢\tDecoding and Output Generation\n",
      "\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for large language model students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for large language model students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "{\n",
      "\"1\": {\n",
      "\"mcq\": \"What is the main focus of Large Language Models (LLMs)?\",\n",
      "\"options\": {\n",
      "\"a\": \"Image processing\",\n",
      "\"b\": \"Language processing\",\n",
      "\"c\": \"Speech recognition\",\n",
      "\"d\": \"Data visualization\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"2\": {\n",
      "\"mcq\": \"Which model was released in 2020 and contains 175 billion parameters?\",\n",
      "\"options\": {\n",
      "\"a\": \"GPT-1\",\n",
      "\"b\": \"GPT-2\",\n",
      "\"c\": \"GPT-3\",\n",
      "\"d\": \"GPT-4\"\n",
      "},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"3\": {\n",
      "\"mcq\": \"What type of learning techniques are used to train Large Language Models?\",\n",
      "\"options\": {\n",
      "\"a\": \"Supervised learning\",\n",
      "\"b\": \"Unsupervised learning\",\n",
      "\"c\": \"Reinforcement learning\",\n",
      "\"d\": \"Semi-supervised learning\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"4\": {\n",
      "\"mcq\": \"Which component of Large Language Model architecture is responsible for capturing dependencies and relationships?\",\n",
      "\"options\": {\n",
      "\"a\": \"Feedforward layers\",\n",
      "\"b\": \"Embedding layers\",\n",
      "\"c\": \"Attention layers\",\n",
      "\"d\": \"Output generation\"\n",
      "},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"5\": {\n",
      "\"mcq\": \"What determines the architecture of a Large Language Model?\",\n",
      "\"options\": {\n",
      "\"a\": \"Color of the text\",\n",
      "\"b\": \"Objective of the model design\",\n",
      "\"c\": \"Size of the paper\",\n",
      "\"d\": \"Number of words in the text\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "}\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "# How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response = generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\": SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:1732\n",
      "Prompt Tokens:1353\n",
      "Completion Tokens:379\n",
      "Total Cost:0.001245\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'mcq': 'What is the main focus of Large Language Models (LLMs)?',\n",
       "  'options': {'a': 'Image processing',\n",
       "   'b': 'Language processing',\n",
       "   'c': 'Speech recognition',\n",
       "   'd': 'Data visualization'},\n",
       "  'correct': 'b'},\n",
       " '2': {'mcq': 'Which model was released in 2020 and contains 175 billion parameters?',\n",
       "  'options': {'a': 'GPT-1', 'b': 'GPT-2', 'c': 'GPT-3', 'd': 'GPT-4'},\n",
       "  'correct': 'c'},\n",
       " '3': {'mcq': 'What type of learning techniques are used to train Large Language Models?',\n",
       "  'options': {'a': 'Supervised learning',\n",
       "   'b': 'Unsupervised learning',\n",
       "   'c': 'Reinforcement learning',\n",
       "   'd': 'Semi-supervised learning'},\n",
       "  'correct': 'b'},\n",
       " '4': {'mcq': 'Which component of Large Language Model architecture is responsible for capturing dependencies and relationships?',\n",
       "  'options': {'a': 'Feedforward layers',\n",
       "   'b': 'Embedding layers',\n",
       "   'c': 'Attention layers',\n",
       "   'd': 'Output generation'},\n",
       "  'correct': 'c'},\n",
       " '5': {'mcq': 'What determines the architecture of a Large Language Model?',\n",
       "  'options': {'a': 'Color of the text',\n",
       "   'b': 'Objective of the model design',\n",
       "   'c': 'Size of the paper',\n",
       "   'd': 'Number of words in the text'},\n",
       "  'correct': 'b'}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "        ]\n",
    "    )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'What is the main focus of Large Language Models (LLMs)?',\n",
       "  'Choices': 'a: Image processing | b: Language processing | c: Speech recognition | d: Data visualization',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which model was released in 2020 and contains 175 billion parameters?',\n",
       "  'Choices': 'a: GPT-1 | b: GPT-2 | c: GPT-3 | d: GPT-4',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'What type of learning techniques are used to train Large Language Models?',\n",
       "  'Choices': 'a: Supervised learning | b: Unsupervised learning | c: Reinforcement learning | d: Semi-supervised learning',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which component of Large Language Model architecture is responsible for capturing dependencies and relationships?',\n",
       "  'Choices': 'a: Feedforward layers | b: Embedding layers | c: Attention layers | d: Output generation',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'What determines the architecture of a Large Language Model?',\n",
       "  'Choices': 'a: Color of the text | b: Objective of the model design | c: Size of the paper | d: Number of words in the text',\n",
       "  'Correct': 'b'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"machinelearning.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04_03_2024_11_51_08'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
